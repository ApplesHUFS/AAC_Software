"""
AAC ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

OpenAI API ëŒ€ì‹  ì‚¬ìš©í•  1-3B ê·œëª¨ì˜ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
Phi-3.5-Vision ê¸°ë°˜ìœ¼ë¡œ AAC ì¹´ë“œ í•´ì„ì— íŠ¹í™”ëœ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
"""

import os
import json
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR
from transformers import AutoProcessor, get_linear_schedule_with_warmup
import wandb
from tqdm import tqdm
import numpy as np
from pathlib import Path
import argparse
from datetime import datetime
import logging
from typing import Dict, List, Optional

# í”„ë¡œì íŠ¸ ëª¨ë“ˆë“¤
import sys
sys.path.append(str(Path(__file__).parent))

from config.train_config import TRAIN_CONFIG
from models.aac_multimodal_model import AACMultimodalModel
from data.dataset import create_dataloaders
from utils.metrics import EvaluationMetrics, calculate_perplexity


class AACTrainer:
    """AAC ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ íŠ¸ë ˆì´ë„ˆ"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.device = torch.device(config['device'])
        
        # ë¡œê¹… ì„¤ì •
        self.setup_logging()
        
        # ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        self.model = None
        self.processor = None
        self.optimizer = None
        self.scheduler = None
        
        # ë°ì´í„°ë¡œë”
        self.train_loader = None
        self.val_loader = None
        self.test_loader = None
        
        # í‰ê°€ ë©”íŠ¸ë¦­
        self.evaluator = EvaluationMetrics()
        
        # í•™ìŠµ ìƒíƒœ
        self.current_epoch = 0
        self.global_step = 0
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        
        # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬
        self.checkpoint_dir = Path(config['checkpoint_dir'])
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬
        self.log_dir = Path(config['log_dir'])
        self.log_dir.mkdir(parents=True, exist_ok=True)
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.log_dir / 'training.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def initialize_model(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        self.logger.info("ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        
        # í”„ë¡œì„¸ì„œ ë¡œë“œ
        self.processor = AutoProcessor.from_pretrained(
            self.config['base_model'], 
            trust_remote_code=True
        )
        
        # íŠ¹ìˆ˜ í† í° ì¶”ê°€
        special_tokens = list(self.config['special_tokens'].values())
        self.processor.tokenizer.add_special_tokens({
            'additional_special_tokens': special_tokens
        })
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = AACMultimodalModel(self.config)
        
        # ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        self.model = self.model.to(self.device)
        
        # ë©€í‹° GPU ì„¤ì •
        if torch.cuda.device_count() > 1 and self.config.get('use_ddp', False):
            self.model = nn.DataParallel(self.model)
        
        self.logger.info(f"ëª¨ë¸ì´ {self.device}ì— ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        param_count = sum(p.numel() for p in self.model.parameters())
        self.logger.info(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {param_count:,}")
    
    def initialize_data(self):
        """ë°ì´í„°ë¡œë” ì´ˆê¸°í™”"""
        self.logger.info("ë°ì´í„°ë¡œë” ì´ˆê¸°í™” ì¤‘...")
        
        # ë°ì´í„° ê²½ë¡œ ì„¤ì •
        data_path = os.path.join(self.config['processed_data'], 'dataset_completed.json')
        images_folder = self.config['images_folder']
        
        if not os.path.exists(data_path):
            raise FileNotFoundError(f"ë°ì´í„°ì…‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        self.train_loader, self.val_loader, self.test_loader = create_dataloaders(
            data_path=data_path,
            images_folder=images_folder,
            processor=self.processor,
            config=self.config
        )
        
        self.logger.info("ë°ì´í„°ë¡œë” ì´ˆê¸°í™” ì™„ë£Œ")
    
    def initialize_optimizer(self):
        """ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”"""
        self.logger.info("ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™” ì¤‘...")
        
        # íŒŒë¼ë¯¸í„° ê·¸ë£¹ ì„¤ì • (LoRAì¸ ê²½ìš° trainable parametersë§Œ)
        if self.config.get('use_lora', False):
            trainable_params = [p for p in self.model.parameters() if p.requires_grad]
            param_groups = [{'params': trainable_params}]
        else:
            param_groups = [{'params': self.model.parameters()}]
        
        # ì˜µí‹°ë§ˆì´ì €
        self.optimizer = AdamW(
            param_groups,
            lr=self.config['learning_rate'],
            weight_decay=self.config['weight_decay'],
            betas=(self.config['beta1'], self.config['beta2']),
            eps=self.config['epsilon']
        )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬
        total_steps = len(self.train_loader) * self.config['num_epochs']
        warmup_steps = self.config['warmup_steps']
        
        self.scheduler = get_linear_schedule_with_warmup(
            self.optimizer,
            num_warmup_steps=warmup_steps,
            num_training_steps=total_steps
        )
        
        self.logger.info("ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™” ì™„ë£Œ")
    
    def train_epoch(self) -> Dict[str, float]:
        """í•œ ì—í¬í¬ í•™ìŠµ"""
        self.model.train()
        
        total_loss = 0.0
        total_samples = 0
        
        progress_bar = tqdm(
            self.train_loader, 
            desc=f"Epoch {self.current_epoch + 1}/{self.config['num_epochs']}"
        )
        
        for batch_idx, batch in enumerate(progress_bar):
            # ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                    for k, v in batch.items()}
            
            # Forward pass
            outputs = self.model(
                input_ids=batch['input_ids'],
                pixel_values=batch.get('pixel_values'),
                attention_mask=batch['attention_mask'],
                labels=batch['labels']
            )
            
            loss = outputs['loss']
            
            # Gradient accumulation
            loss = loss / self.config['gradient_accumulation_steps']
            
            # Backward pass
            loss.backward()
            
            # Gradient clipping
            if self.config.get('gradient_clipping', 0) > 0:
                torch.nn.utils.clip_grad_norm_(
                    self.model.parameters(), 
                    self.config['gradient_clipping']
                )
            
            # ì˜µí‹°ë§ˆì´ì € ìŠ¤í…
            if (batch_idx + 1) % self.config['gradient_accumulation_steps'] == 0:
                self.optimizer.step()
                self.scheduler.step()
                self.optimizer.zero_grad()
                self.global_step += 1
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            total_loss += loss.item() * self.config['gradient_accumulation_steps']
            total_samples += batch['input_ids'].size(0)
            
            # Progress bar ì—…ë°ì´íŠ¸
            avg_loss = total_loss / (batch_idx + 1)
            progress_bar.set_postfix({
                'loss': f'{avg_loss:.4f}',
                'lr': f'{self.scheduler.get_last_lr()[0]:.2e}'
            })
            
            # ë¡œê¹…
            if self.global_step % self.config['logging_steps'] == 0:
                self.logger.info(
                    f"Step {self.global_step}, Loss: {avg_loss:.4f}, "
                    f"LR: {self.scheduler.get_last_lr()[0]:.2e}"
                )
                
                # Wandb ë¡œê¹…
                if wandb.run:
                    wandb.log({
                        'train/loss': avg_loss,
                        'train/learning_rate': self.scheduler.get_last_lr()[0],
                        'train/step': self.global_step
                    })
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if self.global_step % self.config['save_steps'] == 0:
                self.save_checkpoint()
        
        return {
            'loss': total_loss / len(self.train_loader),
            'perplexity': calculate_perplexity([total_loss / len(self.train_loader)])
        }
    
    def save_checkpoint(self):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint = {
            'epoch': self.current_epoch,
            'global_step': self.global_step,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_val_loss': self.best_val_loss,
            'config': self.config
        }
        
        checkpoint_path = self.checkpoint_dir / f"checkpoint_step_{self.global_step}.pt"
        torch.save(checkpoint, checkpoint_path)
        
        self.logger.info(f"ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {checkpoint_path}")
    
    def train(self):
        """ë©”ì¸ í•™ìŠµ í•¨ìˆ˜ - ê°„ë‹¨í•œ ë²„ì „"""
        self.logger.info("AAC ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        print("""
========================================
  AAC ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
========================================

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” OpenAI APIë¥¼ ëŒ€ì²´í•  1-3B ê·œëª¨ì˜
ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- Phi-3.5-Vision ê¸°ë°˜ ì•„í‚¤í…ì²˜
- AAC ì¹´ë“œ ì´ë¯¸ì§€ í•´ì„ íŠ¹í™”
- í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ê°œì¸í™”
- LoRA íŒŒì¸íŠœë‹ ì§€ì›

í•„ìš”í•œ ë°ì´í„°:
- dataset/processed/dataset_completed.json
- dataset/images/ (AAC ì¹´ë“œ ì´ë¯¸ì§€ë“¤)

ì„¤ì • íŒŒì¼: train/config/train_config.py
        """)
        
        # ê¸°ë³¸ ì„¤ì • ì¶œë ¥
        print(f"\ní˜„ì¬ ì„¤ì •:")
        print(f"- ëª¨ë¸: {self.config['model_type']} ({self.config['model_size']})")
        print(f"- ë°°ì¹˜ í¬ê¸°: {self.config['batch_size']}")
        print(f"- í•™ìŠµë¥ : {self.config['learning_rate']}")
        print(f"- ì—í¬í¬: {self.config['num_epochs']}")
        print(f"- LoRA ì‚¬ìš©: {self.config.get('use_lora', False)}")
        print(f"- ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ë°ì´í„° ê²½ë¡œ ì²´í¬
        data_path = os.path.join(self.config['processed_data'], 'dataset_completed.json')
        images_path = self.config['images_folder']
        
        if not os.path.exists(data_path):
            print(f"\nâŒ ì˜¤ë¥˜: ë°ì´í„°ì…‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ê²½ë¡œ: {data_path}")
            print(f"\në¨¼ì € data_prepare.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
            return
        
        if not os.path.exists(images_path):
            print(f"\nâŒ ì˜¤ë¥˜: ì´ë¯¸ì§€ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ê²½ë¡œ: {images_path}")
            return
        
        print(f"\nâœ… ë°ì´í„° ê²½ë¡œ í™•ì¸ ì™„ë£Œ")
        print(f"- ë°ì´í„°ì…‹: {data_path}")
        print(f"- ì´ë¯¸ì§€: {images_path}")
        
        # í•„ìš”í•œ íŒ¨í‚¤ì§€ ì²´í¬
        try:
            from transformers import Phi3VForCausalLM
            print(f"âœ… Transformers íŒ¨í‚¤ì§€ í™•ì¸")
        except ImportError:
            print(f"âŒ ì˜¤ë¥˜: transformers íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print(f"pip install transformers ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return
        
        try:
            from peft import LoraConfig
            print(f"âœ… PEFT íŒ¨í‚¤ì§€ í™•ì¸")
        except ImportError:
            print(f"âŒ ì˜¤ë¥˜: peft íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print(f"pip install peft ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return
        
        print(f"\nğŸš€ ëª¨ë“  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"\nì‹¤ì œ í•™ìŠµì„ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë‹¨ê³„ë¥¼ ë”°ë¼í•˜ì„¸ìš”:")
        print(f"1. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install -r train/requirements.txt")
        print(f"2. GPU ë©”ëª¨ë¦¬ í™•ì¸ (16GB+ ê¶Œì¥)")
        print(f"3. í•™ìŠµ ì‹¤í–‰: python train/train.py --wandb --full-train")
        
        print(f"\nâš ï¸  ì£¼ì˜ì‚¬í•­:")
        print(f"- ì²« ì‹¤í–‰ì‹œ Phi-3.5-Vision ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì•½ 7GB)")
        print(f"- í•™ìŠµ ì‹œê°„: GPUì— ë”°ë¼ ìˆ˜ ì‹œê°„~ìˆ˜ì¼")
        print(f"- ì²´í¬í¬ì¸íŠ¸ëŠ” train/checkpoints/ì— ì €ì¥ë©ë‹ˆë‹¤")

        # --full-train í”Œë˜ê·¸ê°€ ìˆì„ ë•Œë§Œ ì‹¤ì œ í•™ìŠµ ì‹¤í–‰
        if hasattr(self, 'full_train') and self.full_train:
            print(f"\nğŸ‹ï¸â€â™‚ï¸ ì‹¤ì œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            # ì‹¤ì œ í•™ìŠµ ë¡œì§
            try:
                # ì´ˆê¸°í™”
                self.initialize_model()
                self.initialize_data()
                self.initialize_optimizer()
                
                # Wandb ì´ˆê¸°í™”
                if self.config.get('use_wandb', False):
                    wandb.init(
                        project="aac-multimodal",
                        config=self.config,
                        name=f"aac_train_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    )
                
                # í•™ìŠµ ë£¨í”„
                for epoch in range(self.config['num_epochs']):
                    self.current_epoch = epoch
                    
                    # ì—í¬í¬ í•™ìŠµ
                    train_metrics = self.train_epoch()
                    
                    self.logger.info(
                        f"Epoch {epoch + 1}/{self.config['num_epochs']} - "
                        f"Train Loss: {train_metrics['loss']:.4f}"
                    )
                    
                    # Early stopping ì²´í¬
                    if self.patience_counter >= self.config['early_stopping_patience']:
                        self.logger.info("Early stopping triggered")
                        break
                
                self.logger.info("í•™ìŠµ ì™„ë£Œ")
                
            except Exception as e:
                self.logger.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                raise


def main():
    parser = argparse.ArgumentParser(description='AAC ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í•™ìŠµ')
    parser.add_argument('--config', type=str, help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)')
    parser.add_argument('--wandb', action='store_true', help='Wandb ë¡œê¹… ì‚¬ìš©')
    parser.add_argument('--resume', type=str, help='ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘')
    parser.add_argument('--full-train', action='store_true', help='ì‹¤ì œ í•™ìŠµ ì‹¤í–‰')
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = TRAIN_CONFIG.copy()
    
    if args.config:
        with open(args.config, 'r') as f:
            custom_config = json.load(f)
        config.update(custom_config)
    
    if args.wandb:
        config['use_wandb'] = True
    
    # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™” ë° í•™ìŠµ
    trainer = AACTrainer(config)
    trainer.full_train = args.full_train  # ì‹¤ì œ í•™ìŠµ ì—¬ë¶€ ì„¤ì •
    trainer.train()


if __name__ == "__main__":
    main()